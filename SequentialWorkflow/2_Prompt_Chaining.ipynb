{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ouHHhyngtcuX",
        "outputId": "a79bfd96-38bb-460e-ffdb-3e850b388228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.72)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.4.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.4-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m153.2/153.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.6.4 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.0 ormsgpack-1.10.0\n"
          ]
        }
      ],
      "source": [
        "! pip install langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph,START,END"
      ],
      "metadata": {
        "id": "P6i-6p0itpqV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_ACCESS_TOKEN\"] = getpass(\"Enter your secret: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flz3pXODtz5g",
        "outputId": "56cb39d8-e59c-42a3-ba0a-c96714c0c496"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your secret: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community langchain-huggingface"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7Wzs4lJuUVU",
        "outputId": "008da30e-2375-4360-b56c-43c03e52ba5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.12)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.33.4 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.34.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (25.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (1.1.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-huggingface, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.27 langchain-huggingface-0.3.1 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"deepseek-ai/DeepSeek-R1\",\n",
        "    task=\"text-generation\",\n",
        "    huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_ACCESS_TOKEN\"],\n",
        ")\n",
        "\n",
        "model = ChatHuggingFace(llm=llm)"
      ],
      "metadata": {
        "id": "XDTbDvNAuJPc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "class BlogState(TypedDict):\n",
        "    title: str\n",
        "    outline: str\n",
        "    content: str"
      ],
      "metadata": {
        "id": "wNBpMSpBuqEA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_outline(state:BlogState)->BlogState:\n",
        "    # fetch title\n",
        "    title = state['title']\n",
        "\n",
        "    # call llm gen outline\n",
        "    prompt = f'Generate a detailed outline for a blog on the topic - {title}'\n",
        "    outline = model.invoke(prompt).content\n",
        "\n",
        "    # update state\n",
        "    state['outline'] = outline\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "RfwnDg_0upn8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_blog(state: BlogState) -> BlogState:\n",
        "\n",
        "    title = state['title']\n",
        "    outline = state['outline']\n",
        "\n",
        "    prompt = f'Write a detailed blog on the title - {title} using the follwing outline \\n {outline}'\n",
        "\n",
        "    content = model.invoke(prompt).content\n",
        "\n",
        "    state['content'] = content\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "9BIQrvSzu9Lt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(BlogState)\n",
        "\n",
        "# nodes\n",
        "graph.add_node('create_outline', create_outline)\n",
        "graph.add_node('create_blog', create_blog)\n",
        "\n",
        "# edges\n",
        "graph.add_edge(START, 'create_outline')\n",
        "graph.add_edge('create_outline', 'create_blog')\n",
        "graph.add_edge('create_blog', END)\n",
        "\n",
        "workflow = graph.compile()"
      ],
      "metadata": {
        "id": "A9P9-BWxuSsB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intial_state = {'title': 'Rise of AI in India'}\n",
        "final_state = workflow.invoke(intial_state)\n",
        "\n",
        "print(final_state)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3klmcT0fv2V-",
        "outputId": "6b94c89b-e81f-4d16-8105-6031da995595"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'Rise of AI in India', 'outline': \"<think>\\nOkay, so the user wants me to generate a detailed outline for a blog about the rise of AI in India. Hmm, first, I need to make sure I cover all the important aspects. Let's start with an introduction to set the context. India has been making strides in technology, so explaining how AI is part of that growth makes sense.\\n\\nI should break down the outline into sections. Maybe start with an intro that defines AI and gives an overview of its growth in India. Then, move into the historical context. When did AI start gaining traction there? Important milestones would be good here, like government initiatives or key projects.\\n\\nNext, I should consider the industries adopting AI. Healthcare, agriculture, finance, education, retail, and manufacturing come to mind. Each sector can be a subpoint with examples of Indian companies or programs using AI. For instance, in healthcare, there are startups using AI for diagnostics. In agriculture, maybe crop prediction tools.\\n\\nThe AI ecosystem in India could be a separate section. This would include startups, research institutions, and collaborations. Highlighting successful startups and any partnerships between academia and industry would show the collaborative environment. Also, government policies like the National AI Strategy should be mentioned here.\\n\\nEducation and skill development are crucial. How is India preparing its workforce for AI? Maybe talk about courses in universities, online platforms, and training programs. It's also important to address the digital divide and accessibility issues, ensuring all regions benefit.\\n\\nChallenges and ethical considerations can't be ignored. Data privacy, job displacement, and ethical AI use are key points here. Including India's stance on regulations and existing frameworks would add depth. Case studies would make this section more engaging. Success stories like Flipkart or Swiggy using AI, as well as social impact projects in rural areas or language preservation.\\n\\nFuture prospects could discuss upcoming trends and India's potential role globally. Predictions for the next decade might be interesting. The conclusion should summarize and motivate readers. Additional resources would help those wanting to explore further.\\n\\nWait, should I check if the user is targeting a specific audience? Probably tech enthusiasts, professionals, or businesses interested in AI in India. They might want both high-level overview and specific examples. Need to ensure the outline is comprehensive but not too technical. Also, maybe suggest including statistics or recent data to support points. Oh right, the case studies part might need real examples, so advising to research specific Indian companies would be helpful. Alright, I think that's a solid structure. Let me organize these thoughts into sections and subpoints.\\n</think>\\n\\n**Blog Outline: The Rise of AI in India**  \\n\\n---\\n\\n### **1. Introduction**  \\n- **Hook**: Begin with a compelling statistic or story (e.g., India‚Äôs AI market projected to reach $7.8 billion by 2025).  \\n- **Brief Definition**: What is AI? A simple explanation of artificial intelligence.  \\n- **Thesis Statement**: India is emerging as a global hub for AI innovation, driven by talent, policy, and unique market needs.  \\n\\n---\\n\\n### **2. The Historical Context of AI in India**  \\n- **Early Adoption**:  \\n  - Initial steps in academia (e.g., IITs, IISc research in the 1990s‚Äì2000s).  \\n  - Role of IT giants like TCS and Infosys in laying the groundwork.  \\n- **Key Milestones**:  \\n  - Launch of the **National AI Strategy** (2018) by NITI Aayog.  \\n  - Formation of institutes like **Wadhwani AI** for social impact.  \\n\\n---\\n\\n### **3. Key Industries Driving AI Adoption**  \\n- **Healthcare**:  \\n  - Startups using AI for diagnostics (e.g., Niramai, Qure.ai).  \\n  - Government projects like **Ayushman Bharat Digital Mission**.  \\n- **Agriculture**:  \\n  - AI-driven crop prediction tools (e.g., CropIn, Microsoft‚Äôs AI-CROP).  \\n  - Drones for precision farming and pest control.  \\n- **Finance**:  \\n  - Fraud detection (e.g., Razorpay, Paytm).  \\n  - Robo-advisors and chatbots (HDFC‚Äôs EVA, ICICI‚Äôs iPal).  \\n- **Education**:  \\n  - Personalized learning platforms (Byju‚Äôs, Unacademy).  \\n- **Retail & E-commerce**:  \\n  - Recommendation engines (Flipkart, Myntra).  \\n- **Manufacturing**:  \\n  - Predictive maintenance and IoT integration.  \\n\\n---\\n\\n### **4. India‚Äôs AI Ecosystem**  \\n- **Startups**:  \\n  - Highlight unicorns and emerging players (e.g., Zoho, MuSigma).  \\n- **Research & Academia**:  \\n  - Centres of Excellence (CoEs) at IITs, IIITs, and partnerships with global tech firms.  \\n- **Government Initiatives**:  \\n  - **Responsible AI for Youth** program.  \\n  - **AI for All** strategy focusing on inclusivity.  \\n- **Corporate Investments**:  \\n  - Reliance Jio‚Äôs collaboration with Google, Tata‚Äôs AI projects.  \\n\\n---\\n\\n### **5. Talent and Skill Development**  \\n- **Education Programs**:  \\n  - AI courses in universities (IIT Madras‚Äô Online Diploma in AI).  \\n  - Platforms like Coursera and upGrad offering certifications.  \\n- **Bridging the Skill Gap**:  \\n  - Initiatives by NASSCOM (FutureSkills Prime) and Google AI for India.  \\n- **Challenges**:  \\n  - Retention of talent amid global competition.  \\n  - Rural-urban divide in access to AI education.  \\n\\n---\\n\\n### **6. Ethical and Societal Challenges**  \\n- **Data Privacy Concerns**:  \\n  - Impact of India‚Äôs Digital Personal Data Protection Act (2023) on AI.  \\n- **Bias and Fairness**:  \\n  - Risks of AI replicating societal biases (e.g., caste, gender).  \\n- **Job Displacement**:  \\n  - Debate on AI automating roles vs. creating new opportunities.  \\n- **Regulatory Frameworks**:  \\n  - Need for standardized AI ethics guidelines.  \\n\\n---\\n\\n### **7. Case Studies**  \\n- **Success Stories**:  \\n  - Swiggy‚Äôs AI-driven delivery optimization.  \\n  - Detect Technologies‚Äô AI for industrial safety.  \\n- **Social Impact**:  \\n  - AI for disaster management (e.g., flood prediction in Assam).  \\n  - Project DIVyA (Digital Inclusion for Value-added Services) in rural India.  \\n- **Indigenous Innovation**:  \\n  - Bhashini‚Äôs AI for Indian language translation.  \\n\\n---\\n\\n### **8. The Road Ahead: India‚Äôs AI Future**  \\n- **Trends to Watch**:  \\n  - AI in climate tech and sustainability.  \\n  - Generative AI adoption in creative industries.  \\n- **Global Collaboration**:  \\n  - India‚Äôs role in the Global Partnership on AI (GPAI).  \\n  - Opportunities for US-India and India-EU AI partnerships.  \\n- **Vision for 2030**:  \\n  - Becoming a ‚ÄúVishwa Guru‚Äù in AI for inclusive growth.  \\n\\n---\\n\\n### **9. Conclusion**  \\n- Recap India‚Äôs rapid AI growth and unique position as a tech democracy.  \\n- Call to action for policymakers, businesses, and citizens to embrace AI responsibly.  \\n- Optimistic closing note on India‚Äôs potential to lead AI for social good.  \\n\\n---\\n\\n### **10. Additional Resources**  \\n- Links to government reports (NITI Aayog‚Äôs National AI Strategy).  \\n- Recommended books, podcasts, and courses on AI in India.  \\n- List of AI startups and research institutes to follow.  \\n\\n---\\n\\nThis outline balances technical insights, real-world examples, and societal implications, catering to entrepreneurs, policymakers, tech enthusiasts, and general readers. Adjust depth per section based on audience expertise!\", 'content': \"<think>\\nAlright, let's put together the detailed blog based on the outline. The user wants a comprehensive yet engaging article on the rise of AI in India. I'll start with a strong hook to grab attention, maybe a striking statistic. Then define AI briefly to ensure all readers are on the same page. \\n\\nNext, the historical context should highlight India's early steps in AI through academia and IT companies. Mentioning specific institutions like IITs and initiatives like the National AI Strategy adds credibility. \\n\\nMoving to key industries, I'll need to provide examples for each sector. For healthcare, Niramai and Qure.ai are good examples. In agriculture, CropIn and Microsoft‚Äôs projects stand out. Finance sector examples like Razorpay and HDFC‚Äôs chatbot can illustrate practical applications. \\n\\nThe AI ecosystem section should showcase startups, research centers, and government policies. Including unicorns and collaborations like Reliance Jio and Google will show corporate involvement. \\n\\nEducation and skill development are crucial. I'll talk about courses from IIT Madras and platforms like Coursera, as well as challenges like the rural-urban divide. \\n\\nEthical challenges must be addressed carefully. Data privacy laws and job displacement are key points here. Including India's Digital Personal Data Protection Act adds timeliness. \\n\\nCase studies should highlight success stories and social impact. Swiggy‚Äôs delivery optimization and projects in disaster management are relatable examples. India's Bhashini for language translation shows indigenous innovation.\\n\\nLooking ahead, trends like AI in climate tech and global collaborations position India's future role. The conclusion should reinforce India's potential and urge responsible adoption.\\n\\nI need to ensure the blog flows smoothly, with each section linking logically. Avoiding overly technical terms will keep it accessible. Including recent data (like 2023 stats) will make it current. Also, mentioning NASSCOM and other organizations provides authoritative backing. \\n\\nI should check that each subsection is concise but informative. Maybe add bullet points in sections like industries for readability. Emphasizing social impact will resonate with readers interested in ethical tech. Concluding with a call to action motivates engagement. \\n\\nFinally, additional resources should guide readers to explore further. Overall, balancing facts with engaging storytelling will make the blog informative and compelling.\\n</think>\\n\\n**The Rise of AI in India: Transforming a Billion Lives**  \\n\\n---\\n\\n### **Introduction**  \\nImagine a farmer in rural Maharashtra receiving real-time crop advice via a WhatsApp chatbot, or a doctor in Raipur using AI to detect tuberculosis from an X-ray scan in seconds. These are not futuristic fantasies‚Äîthey are today‚Äôs reality in India. With its AI market set to reach **$7.8 billion by 2025**, India is leveraging artificial intelligence to solve complex challenges, fuel economic growth, and position itself as a global tech leader. From agriculture to healthcare, India‚Äôs AI journey is reshaping lives at an unprecedented scale.\\n\\n---\\n\\n### **Historical Context: From Labs to Mainstream**  \\nIndia‚Äôs AI roots trace back to academia in the 1990s, where institutions like **IITs** and **IISc Bangalore** pioneered early research. However, the true catalyst came in the 2010s, when startups and IT giants like **Infosys** and **TCS** began integrating AI into enterprise solutions. The government‚Äôs 2018 **National AI Strategy**, anchored by NITI Aayog, marked a turning point, identifying healthcare, agriculture, and education as priority sectors. Initiatives like **Wadhwani AI**‚Äîa nonprofit developing AI for maternal health and crop yields‚Äîshowcased India‚Äôs focus on social impact. Today, India ranks **1st in AI skill penetration** and **2nd in AI research publications** globally.\\n\\n---\\n\\n### **AI in Action: Revolutionizing Key Industries**  \\n#### **1. Healthcare**  \\nAI is bridging India‚Äôs doctor-patient gap (1:1,511 ratio). Startups like **Niramai** use thermal imaging and AI to detect breast cancer non-invasively, while **Qure.ai** analyzes X-rays for TB in seconds. The government‚Äôs **Ayushman Bharat Digital Mission** aims to create AI-powered health IDs for 1.4 billion citizens.  \\n\\n#### **2. Agriculture**  \\nFarmers use **CropIn‚Äôs** AI platform to predict yields and reduce waste, while Microsoft‚Äôs **AI-CROP** initiative helps combat crop diseases. Drones map fields, and chatbots like **IBM‚Äôs Mitra** deliver localized advice in regional languages.  \\n\\n#### **3. Finance**  \\nFrom **Paytm‚Äôs** fraud detection systems to **HDFC Bank‚Äôs** AI chatbot **EVA**, India‚Äôs fintech sector thrives on AI. The RBI‚Äôs regulatory sandbox encourages innovations like **CreditVidya**, which uses alternative data to assess loan eligibility.  \\n\\n#### **4. Education**  \\nEdtech giants like **Byju‚Äôs** and **Unacademy** personalize learning with adaptive algorithms. The government‚Äôs **DIKSHA** platform uses AI to translate content into 22 languages, reaching 150 million students.  \\n\\n#### **5. Retail & Manufacturing**  \\n**Flipkart** uses AI to forecast demand and optimize deliveries, while **Tata Steel** employs predictive maintenance to reduce downtime. Startups like **Stellapps** track dairy supply chains using IoT and AI.  \\n\\n---\\n\\n### **The AI Ecosystem: Startups, Research, and Policy**  \\nIndia‚Äôs AI landscape is a vibrant mix of **1,900+ startups**, including unicorns like **Zoho** and **MuSigma**. Research thrives at IITs and through partnerships like **Google‚Äôs AI Research Lab** in Bangalore. The government‚Äôs **Responsible AI for Youth** program trains students to build ethical AI solutions, while states like Telangana and Tamil Nadu launch AI missions to boost governance.  \\n\\n---\\n\\n### **Building a Skilled Workforce**  \\nIndia graduates over **2.5 million STEM students** annually, but only 3% possess advanced AI skills. To bridge this gap:  \\n- **IIT Madras** offers an online diploma in AI.  \\n- **NASSCOM‚Äôs FutureSkills Prime** reskills professionals.  \\n- **Google AI for India** funds scholarships for underrepresented groups.  \\n\\nYet, disparities persist‚Äîonly 15% of rural youth access digital skilling programs.  \\n\\n---\\n\\n### **Ethical AI: Navigating Challenges**  \\nIndia faces a tightrope walk between innovation and ethics:  \\n- **Data Privacy**: The 2023 **Digital Personal Data Protection Act** mandates accountability for AI firms.  \\n- **Bias**: Algorithms trained on skewed data risk amplifying caste or gender biases.  \\n- **Job Loss Fears**: While AI could displace 69 million jobs by 2030, it may create 97 million new roles (WEF).  \\n\\nOrganizations like **Wadhwani AI** advocate for fairness and transparency, proving tech can be both powerful and ethical.  \\n\\n---\\n\\n### **Case Studies: AI for Good**  \\n- **Healthcare**: **Aarogya Setu**, India‚Äôs COVID-19 contact tracing app, used AI to predict hotspots and curb infections.  \\n- **Agriculture**: Pune-based **Intello Labs** employs AI to grade crop quality, empowering farmers to negotiate better prices.  \\n- **Language**: **Bhashini**, India‚Äôs AI translation tool, breaks language barriers by supporting 500+ dialect pairs.  \\n\\n---\\n\\n### **The Road Ahead: India‚Äôs AI Ambitions**  \\nBy 2030, India aims to:  \\n1. Lead in **AI for climate resilience**, using predictive models for floods and droughts.  \\n2. Build a $1 trillion digital economy fueled by AI.  \\n3. Expand collaborations via the **Global Partnership on AI (GPAI)**.  \\n\\nTrends like generative AI (e.g., **Ola‚Äôs Krutim**) and AI-driven public services (e.g., **AI-powered traffic management**) will dominate the next decade.  \\n\\n---\\n\\n### **Conclusion**  \\nIndia‚Äôs AI rise isn‚Äôt just about technology‚Äîit‚Äôs a story of **democratizing progress**. By prioritizing inclusivity, ethics, and grassroots innovation, India can chart a unique path where AI uplifts farmers, students, and entrepreneurs alike. As Sundar Pichai aptly said, *‚ÄúIndia will be the global engine for AI innovation.‚Äù* The challenge now is to ensure no one is left behind.  \\n\\n--- \\n\\n**Explore Further**:  \\n- [NITI Aayog‚Äôs National AI Strategy](https://www.niti.gov.in/)  \\n- Documentary: *AI: Shaping India‚Äôs Future* (ET Now)  \\n- Courses: IIT Madras‚Äô *Introduction to AI* (on Coursera).  \\n\\nLet‚Äôs embrace AI not as a disruptor, but as a catalyst for an equitable, empowered India. üåü\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_state['outline'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBcD0iUFwIw7",
        "outputId": "c02f0464-7e7c-4601-eed0-006e67907a68"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "Okay, so the user wants me to generate a detailed outline for a blog about the rise of AI in India. Hmm, first, I need to make sure I cover all the important aspects. Let's start with an introduction to set the context. India has been making strides in technology, so explaining how AI is part of that growth makes sense.\n",
            "\n",
            "I should break down the outline into sections. Maybe start with an intro that defines AI and gives an overview of its growth in India. Then, move into the historical context. When did AI start gaining traction there? Important milestones would be good here, like government initiatives or key projects.\n",
            "\n",
            "Next, I should consider the industries adopting AI. Healthcare, agriculture, finance, education, retail, and manufacturing come to mind. Each sector can be a subpoint with examples of Indian companies or programs using AI. For instance, in healthcare, there are startups using AI for diagnostics. In agriculture, maybe crop prediction tools.\n",
            "\n",
            "The AI ecosystem in India could be a separate section. This would include startups, research institutions, and collaborations. Highlighting successful startups and any partnerships between academia and industry would show the collaborative environment. Also, government policies like the National AI Strategy should be mentioned here.\n",
            "\n",
            "Education and skill development are crucial. How is India preparing its workforce for AI? Maybe talk about courses in universities, online platforms, and training programs. It's also important to address the digital divide and accessibility issues, ensuring all regions benefit.\n",
            "\n",
            "Challenges and ethical considerations can't be ignored. Data privacy, job displacement, and ethical AI use are key points here. Including India's stance on regulations and existing frameworks would add depth. Case studies would make this section more engaging. Success stories like Flipkart or Swiggy using AI, as well as social impact projects in rural areas or language preservation.\n",
            "\n",
            "Future prospects could discuss upcoming trends and India's potential role globally. Predictions for the next decade might be interesting. The conclusion should summarize and motivate readers. Additional resources would help those wanting to explore further.\n",
            "\n",
            "Wait, should I check if the user is targeting a specific audience? Probably tech enthusiasts, professionals, or businesses interested in AI in India. They might want both high-level overview and specific examples. Need to ensure the outline is comprehensive but not too technical. Also, maybe suggest including statistics or recent data to support points. Oh right, the case studies part might need real examples, so advising to research specific Indian companies would be helpful. Alright, I think that's a solid structure. Let me organize these thoughts into sections and subpoints.\n",
            "</think>\n",
            "\n",
            "**Blog Outline: The Rise of AI in India**  \n",
            "\n",
            "---\n",
            "\n",
            "### **1. Introduction**  \n",
            "- **Hook**: Begin with a compelling statistic or story (e.g., India‚Äôs AI market projected to reach $7.8 billion by 2025).  \n",
            "- **Brief Definition**: What is AI? A simple explanation of artificial intelligence.  \n",
            "- **Thesis Statement**: India is emerging as a global hub for AI innovation, driven by talent, policy, and unique market needs.  \n",
            "\n",
            "---\n",
            "\n",
            "### **2. The Historical Context of AI in India**  \n",
            "- **Early Adoption**:  \n",
            "  - Initial steps in academia (e.g., IITs, IISc research in the 1990s‚Äì2000s).  \n",
            "  - Role of IT giants like TCS and Infosys in laying the groundwork.  \n",
            "- **Key Milestones**:  \n",
            "  - Launch of the **National AI Strategy** (2018) by NITI Aayog.  \n",
            "  - Formation of institutes like **Wadhwani AI** for social impact.  \n",
            "\n",
            "---\n",
            "\n",
            "### **3. Key Industries Driving AI Adoption**  \n",
            "- **Healthcare**:  \n",
            "  - Startups using AI for diagnostics (e.g., Niramai, Qure.ai).  \n",
            "  - Government projects like **Ayushman Bharat Digital Mission**.  \n",
            "- **Agriculture**:  \n",
            "  - AI-driven crop prediction tools (e.g., CropIn, Microsoft‚Äôs AI-CROP).  \n",
            "  - Drones for precision farming and pest control.  \n",
            "- **Finance**:  \n",
            "  - Fraud detection (e.g., Razorpay, Paytm).  \n",
            "  - Robo-advisors and chatbots (HDFC‚Äôs EVA, ICICI‚Äôs iPal).  \n",
            "- **Education**:  \n",
            "  - Personalized learning platforms (Byju‚Äôs, Unacademy).  \n",
            "- **Retail & E-commerce**:  \n",
            "  - Recommendation engines (Flipkart, Myntra).  \n",
            "- **Manufacturing**:  \n",
            "  - Predictive maintenance and IoT integration.  \n",
            "\n",
            "---\n",
            "\n",
            "### **4. India‚Äôs AI Ecosystem**  \n",
            "- **Startups**:  \n",
            "  - Highlight unicorns and emerging players (e.g., Zoho, MuSigma).  \n",
            "- **Research & Academia**:  \n",
            "  - Centres of Excellence (CoEs) at IITs, IIITs, and partnerships with global tech firms.  \n",
            "- **Government Initiatives**:  \n",
            "  - **Responsible AI for Youth** program.  \n",
            "  - **AI for All** strategy focusing on inclusivity.  \n",
            "- **Corporate Investments**:  \n",
            "  - Reliance Jio‚Äôs collaboration with Google, Tata‚Äôs AI projects.  \n",
            "\n",
            "---\n",
            "\n",
            "### **5. Talent and Skill Development**  \n",
            "- **Education Programs**:  \n",
            "  - AI courses in universities (IIT Madras‚Äô Online Diploma in AI).  \n",
            "  - Platforms like Coursera and upGrad offering certifications.  \n",
            "- **Bridging the Skill Gap**:  \n",
            "  - Initiatives by NASSCOM (FutureSkills Prime) and Google AI for India.  \n",
            "- **Challenges**:  \n",
            "  - Retention of talent amid global competition.  \n",
            "  - Rural-urban divide in access to AI education.  \n",
            "\n",
            "---\n",
            "\n",
            "### **6. Ethical and Societal Challenges**  \n",
            "- **Data Privacy Concerns**:  \n",
            "  - Impact of India‚Äôs Digital Personal Data Protection Act (2023) on AI.  \n",
            "- **Bias and Fairness**:  \n",
            "  - Risks of AI replicating societal biases (e.g., caste, gender).  \n",
            "- **Job Displacement**:  \n",
            "  - Debate on AI automating roles vs. creating new opportunities.  \n",
            "- **Regulatory Frameworks**:  \n",
            "  - Need for standardized AI ethics guidelines.  \n",
            "\n",
            "---\n",
            "\n",
            "### **7. Case Studies**  \n",
            "- **Success Stories**:  \n",
            "  - Swiggy‚Äôs AI-driven delivery optimization.  \n",
            "  - Detect Technologies‚Äô AI for industrial safety.  \n",
            "- **Social Impact**:  \n",
            "  - AI for disaster management (e.g., flood prediction in Assam).  \n",
            "  - Project DIVyA (Digital Inclusion for Value-added Services) in rural India.  \n",
            "- **Indigenous Innovation**:  \n",
            "  - Bhashini‚Äôs AI for Indian language translation.  \n",
            "\n",
            "---\n",
            "\n",
            "### **8. The Road Ahead: India‚Äôs AI Future**  \n",
            "- **Trends to Watch**:  \n",
            "  - AI in climate tech and sustainability.  \n",
            "  - Generative AI adoption in creative industries.  \n",
            "- **Global Collaboration**:  \n",
            "  - India‚Äôs role in the Global Partnership on AI (GPAI).  \n",
            "  - Opportunities for US-India and India-EU AI partnerships.  \n",
            "- **Vision for 2030**:  \n",
            "  - Becoming a ‚ÄúVishwa Guru‚Äù in AI for inclusive growth.  \n",
            "\n",
            "---\n",
            "\n",
            "### **9. Conclusion**  \n",
            "- Recap India‚Äôs rapid AI growth and unique position as a tech democracy.  \n",
            "- Call to action for policymakers, businesses, and citizens to embrace AI responsibly.  \n",
            "- Optimistic closing note on India‚Äôs potential to lead AI for social good.  \n",
            "\n",
            "---\n",
            "\n",
            "### **10. Additional Resources**  \n",
            "- Links to government reports (NITI Aayog‚Äôs National AI Strategy).  \n",
            "- Recommended books, podcasts, and courses on AI in India.  \n",
            "- List of AI startups and research institutes to follow.  \n",
            "\n",
            "---\n",
            "\n",
            "This outline balances technical insights, real-world examples, and societal implications, catering to entrepreneurs, policymakers, tech enthusiasts, and general readers. Adjust depth per section based on audience expertise!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wnx_cF8Hwjfi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}